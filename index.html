<!DOCTYPE html>
<html>
    <head>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-176302866-1"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'UA-176302866-1');
        </script>

        <meta charset="utf-8">
        <title>William Peebles</title>
        <meta name="description" content="Project Page">
        <link rel="stylesheet" href="main.css">
        <link rel="stylesheet" href="https://use.typekit.net/oml3bsz.css">
    </head>
    <body>
        <h1>
            William (Bill) Peebles
        </h1><br>
        <div class="row">
            <div class="column-left">
                <img class="me" src="images/me2023.jpeg" alt="William Peebles"><br>
            </div>
            <!--<div class="column-right pxb">
                <h1>THE PIXEL BENDING BLOG</h1>
                <p>Welcome to the Pixel Bending mini-blog! Here, I'll talk about various topics related to synthesizing images,
                    building deep generative models and more. Click the links below to access the posts:</p>
                <a class="disentangle-button gradient-button" href="blog_posts/disentanglement.html">1. THE MAGIC OF DISENTANGLEMENT</>
                <a class="hessian-button gradient-button">2. THE HESSIAN PENALTY</a>
            </div>-->
            <div class="column-right">
                I'm a research scientist at <a href="https://www.openai.com">OpenAI</a>. Previously, I completed my PhD at Berkeley AI Research advised by <a href="https://people.eecs.berkeley.edu/~efros/">Alyosha Efros</a>.
                Before that, I did my undergrad at MIT where I was advised by
                <a href="https://web.mit.edu/torralba/www/">Antonio Torralba</a>.  I've interned at FAIR, Adobe Research and NVIDIA.
                During my PhD, I was supported by the National Science Foundation's Graduate Research Fellowship Program.<br><br>

                My research focuses on deep learning and artificial intelligence, with a strong emphasis on deep generative models.
                I am especially interested in large-scale generative AI for synthesizing and manipulating visual content.</p><br><br>

                <div style="text-align:center">
                    <a href="https://twitter.com/billpeeb">twitter</a> &#183; <a href="https://github.com/wpeebles">github</a> &#183; <a href="https://scholar.google.com/citations?user=b_RBE3EAAAAJ&hl=en">google scholar</a> &#183; <a href="mailto:peebles@berkeley.edu">email</a>
                </div>
            </div>
        </div>
        <br>

        <h2 style="background: linear-gradient(180deg, rgba(255,255,255,0) 65%, #ff8888 65%);">News</h2><br>
        <b>[Jan 2023]</b> DiT is now natively usable in Hugging Face diffusers <a href="https://github.com/huggingface/diffusers/blob/main/docs/source/en/api/pipelines/dit.mdx">here</a>.<br>
        <b>[Dec 2022]</b> We released a DiT Hugging Face Space <a href="https://huggingface.co/spaces/wpeebles/DiT">here</a>.<br>
        <b>[Dec 2022]</b> DiT code has been released in PyTorch <a href="https://github.com/facebookresearch/DiT">here</a>.<br>
        <b>[Sep 2022]</b> G.pt code has been released in PyTorch <a href="https://github.com/wpeebles/G.pt">here</a>.<br>
        <b>[Jun 2022]</b> GANgealing is a best paper finalist at CVPR'22.<br>
        <b>[Apr 2022]</b> Check out Two Minute Papers' <a href="https://www.youtube.com/watch?v=qtOkktTNs-k">video</a> covering GANgealing!<br>
        <br>
        <h2 style="background: linear-gradient(180deg, rgba(255,255,255,0) 65%, #98caf3 65%);">Publications</h2><br>

        <p class="paper"><video loop autoplay muted playsinline>
            <source src="images/DiT/walks/mq/z-walk-DiT-XL-patch2-res512-vae-ft-ema-3002400-cfg-4.0-rng640-8-grid.mp4" type="video/mp4">
        </video>
            <span><b>Scalable Diffusion Models with Transformers</b>
        <br>William Peebles, Saining Xie
                <br>ICCV 2023 (Oral)<br>
        <a href="DiT.html">project page</a> &#183;
                <a href="https://huggingface.co/spaces/wpeebles/DiT">hugging face space</a> &#183;
                <a href="http://colab.research.google.com/github/facebookresearch/DiT/blob/main/run_DiT.ipynb">colab</a> &#183;
                <a href="http://arxiv.org/abs/2212.09748">paper</a> &#183;
                <a href="https://github.com/facebookresearch/DiT">github</a>
            </span></p>

        <p class="paper"><video loop autoplay muted playsinline>
            <source src="images/Gpt/model_darkmode.mp4" type="video/mp4">
        </video>
            <span><b>Learning to Learn with Generative Models of Neural Network Checkpoints</b>
        <br>William Peebles*, Ilija Radosavovic*, Tim Brooks, Alexei Efros, Jitendra Malik
                <br>
        <a href="Gpt.html">project page</a> &#183;
                <a href="http://arxiv.org/abs/2209.12892">paper</a> &#183;
                <a href="https://github.com/wpeebles/G.pt">github</a>
            </span></p>

        <p class="paper"><video loop autoplay muted playsinline>
            <source src="images/gangealing_visuals/cats_cube_website.mp4" type="video/mp4">
        </video>
            <span><b>GAN-Supervised Dense Visual Alignment</b>
        <br>William Peebles, Jun-Yan Zhu, Richard Zhang, Antonio Torralba, Alexei Efros, Eli Shechtman
                <br>CVPR 2022 (Oral) &#183; <b>Best Paper Finalist</b>
                <br> <a href="https://www.youtube.com/watch?v=qtOkktTNs-k">two minute papers</a> &#183; <a href="https://colab.research.google.com/drive/1JkUjhTjR8MyLxwarJjqnh836BICfocTu?usp=sharing">mixed reality demo</a> &#183; <a href="https://youtu.be/Qa1ASS_NuzE">video</a> &#183; <a href="https://www.wpeebles.com/gangealing">project page</a> &#183; <a href="https://arxiv.org/abs/2112.05143">paper</a> &#183; <a href="https://github.com/wpeebles/gangealing">github</a></span></p>


        <p class="paper"><video loop autoplay muted playsinline>
            <source src="images/hessian.mp4" type="video/mp4">
        </video>
            <span><b>The Hessian Penalty: A Weak Prior for Unsupervised Disentanglement</b>
        <br>William Peebles, John Peebles, Jun-Yan Zhu, Alexei Efros, Antonio Torralba
        <br>ECCV 2020 (Spotlight)
                <br> <a href="https://youtu.be/uZyIcTkSSXA">video</a> &#183; <a href="https://youtu.be/jPl-0EN6S1w">overview in 90 seconds</a> &#183; <a href="hessian-penalty.html">project page</a> &#183; <a href="https://arxiv.org/abs/2008.10599">paper</a> &#183; <a href="https://github.com/wpeebles/hessian_penalty">github</a></span></p>

        <p class="paper"><img src="images/iccv2019.png"
                              alt="GAN reconstructions of images versus the original images.">
            <span><b>Seeing What a GAN Cannot Generate</b>
        <br>David Bau, Jun-Yan Zhu, Jonas Wulff, William Peebles, Hendrik Strobelt, Bolei Zhou, Antonio Torralba
        <br>ICCV 2019 (Oral)
        <br><a href="http://gannotsee.net/">demo</a> &#183;
        <a href="http://ganseeing.csail.mit.edu/">project page</a> &#183;
                <a href="https://arxiv.org/abs/1910.11626">paper</a> &#183;
                <a href="https://github.com/davidbau/ganseeing">github</a></span></p>


        <p class="paper"><img src="images/sig2019.png"
                              alt="A natural image of a building is modified by adding trees and domes.">
            <span><b>Semantic Photo Manipulation with a Generative Image Prior</b>
        <br>David Bau, Hendrik Strobelt, William Peebles, Jonas Wulff, Bolei Zhou, Jun-Yan Zhu, Antonio Torralba
        <br>SIGGRAPH 2019<br><a href="http://ganpaint.io/demo/?project=church">demo</a> &#183;
        <a href="http://ganpaint.io/">project page</a> &#183;
                <a href="https://arxiv.org/abs/2005.07727">paper</a></span></p>

    </body>
</html>